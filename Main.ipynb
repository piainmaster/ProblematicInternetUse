{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Clone Repository"
      ],
      "metadata": {
        "id": "EZisJjliwMeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/piainmaster/ProblematicInternetUse.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaroMv9avprq",
        "outputId": "764cf467-b74c-4492-9239-dbb898e0117f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ProblematicInternetUse'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects:   8% (1/12)\u001b[K\rremote: Counting objects:  16% (2/12)\u001b[K\rremote: Counting objects:  25% (3/12)\u001b[K\rremote: Counting objects:  33% (4/12)\u001b[K\rremote: Counting objects:  41% (5/12)\u001b[K\rremote: Counting objects:  50% (6/12)\u001b[K\rremote: Counting objects:  58% (7/12)\u001b[K\rremote: Counting objects:  66% (8/12)\u001b[K\rremote: Counting objects:  75% (9/12)\u001b[K\rremote: Counting objects:  83% (10/12)\u001b[K\rremote: Counting objects:  91% (11/12)\u001b[K\rremote: Counting objects: 100% (12/12)\u001b[K\rremote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects:   9% (1/11)\u001b[K\rremote: Compressing objects:  18% (2/11)\u001b[K\rremote: Compressing objects:  27% (3/11)\u001b[K\rremote: Compressing objects:  36% (4/11)\u001b[K\rremote: Compressing objects:  45% (5/11)\u001b[K\rremote: Compressing objects:  54% (6/11)\u001b[K\rremote: Compressing objects:  63% (7/11)\u001b[K\rremote: Compressing objects:  72% (8/11)\u001b[K\rremote: Compressing objects:  81% (9/11)\u001b[K\rremote: Compressing objects:  90% (10/11)\u001b[K\rremote: Compressing objects: 100% (11/11)\u001b[K\rremote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 12 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects:   8% (1/12)\rReceiving objects:  16% (2/12)\rReceiving objects:  25% (3/12)\rReceiving objects:  33% (4/12)\rReceiving objects:  41% (5/12)\rReceiving objects:  50% (6/12)\rReceiving objects:  58% (7/12)\rReceiving objects:  66% (8/12)\rReceiving objects:  75% (9/12)\rReceiving objects:  83% (10/12)\rReceiving objects:  91% (11/12)\rReceiving objects: 100% (12/12)\rReceiving objects: 100% (12/12), 7.40 KiB | 7.40 MiB/s, done.\n",
            "Resolving deltas:   0% (0/2)\rResolving deltas:  50% (1/2)\rResolving deltas: 100% (2/2)\rResolving deltas: 100% (2/2), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ProblematicInternetUse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5BfzFwWv8tm",
        "outputId": "f15b6fd7-9704-4b11-d905-75738bacbc8d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ProblematicInternetUse/ProblematicInternetUse/ProblematicInternetUse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Dataset"
      ],
      "metadata": {
        "id": "gaUBZB4Lx3vG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle # install kaggle api client"
      ],
      "metadata": {
        "id": "XTGU5cbUjr5u"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "uohSS3m_juRt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "lZhhsmzw_TMN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c child-mind-institute-problematic-internet-use"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9XZ5dA7jyml",
        "outputId": "db8952a1-ce44-4d48-b17e-0ebba277dc82"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading child-mind-institute-problematic-internet-use.zip to /content/ProblematicInternetUse/ProblematicInternetUse/ProblematicInternetUse\n",
            "100% 6.20G/6.21G [01:15<00:00, 85.4MB/s]\n",
            "100% 6.21G/6.21G [01:15<00:00, 88.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q child-mind-institute-problematic-internet-use.zip -d /content/dataset"
      ],
      "metadata": {
        "id": "aJigru5Zj_N9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Push changes to GitHub"
      ],
      "metadata": {
        "id": "RCG5M_47vp_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"pia.neuwirth@stud.plus.ac.at\"\n",
        "!git config --global user.name \"piainmaster\""
      ],
      "metadata": {
        "id": "a7xJgEvWwlnN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add Main.ipynb\n",
        "!git commit -m \"Updated the notebook with new changes\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89zRDUYPwEV5",
        "outputId": "6586b6e4-bb82-48d9-91a4-f4467e6f3217"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mchild-mind-institute-problematic-internet-use.zip\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main"
      ],
      "metadata": {
        "id": "tPM1A09nzNfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Data"
      ],
      "metadata": {
        "id": "h2u48VBPwR1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "yPekYgsY1PoI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CSV DATA"
      ],
      "metadata": {
        "id": "9S8Zqibl1dTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data sets\n",
        "train_data = pd.read_csv(\"/content/dataset/train.csv\")\n",
        "test_data = pd.read_csv(\"/content/dataset/test.csv\")\n",
        "\n",
        "print(\"Train data shape:\" + str(train_data.shape))\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values in Train Data:\")\n",
        "print(train_data.isnull().sum())"
      ],
      "metadata": {
        "id": "ZRme5h2d1WGn",
        "outputId": "7b3669ed-64c9-4982-bb7f-e1af6696e1ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape:(3960, 82)\n",
            "\n",
            "Missing Values in Train Data:\n",
            "id                                           0\n",
            "Basic_Demos-Enroll_Season                    0\n",
            "Basic_Demos-Age                              0\n",
            "Basic_Demos-Sex                              0\n",
            "CGAS-Season                               1405\n",
            "                                          ... \n",
            "SDS-SDS_Total_Raw                         1351\n",
            "SDS-SDS_Total_T                           1354\n",
            "PreInt_EduHx-Season                        420\n",
            "PreInt_EduHx-computerinternet_hoursday     659\n",
            "sii                                       1224\n",
            "Length: 82, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parquet Data"
      ],
      "metadata": {
        "id": "EN_ICdRP1gY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_folder = '/content/dataset/series_train.parquet'\n",
        "\n",
        "# Get a list of all subfolders (which contain \"id=xxxxx\")\n",
        "subfolders = [f.path for f in os.scandir(dataset_folder) if f.is_dir()]\n",
        "chunk_size = len(subfolders) // 9\n",
        "subfolders_parts = [subfolders[i:i + chunk_size] for i in range(0, len(subfolders), chunk_size)]\n",
        "\n",
        "# If the last chunk is smaller than expected (due to uneven split), it will still work.\n",
        "print(f\"Number of subfolders in each part (except possibly the last): {chunk_size}\")\n",
        "print(f\"Number of parts created: {len(subfolders_parts)}\")"
      ],
      "metadata": {
        "id": "rBTA0C4-5pqU",
        "outputId": "881d1b67-e17e-4243-82a1-53a06f854556",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of subfolders in each part (except possibly the last): 110\n",
            "Number of parts created: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize an empty list to hold DataFrame chunks for each part\n",
        "full_df_parts = []\n",
        "\n",
        "# Process the first 5 parts\n",
        "for idx in range(5):\n",
        "    subfolders_part = subfolders_parts[idx]  # Get the current part\n",
        "    dataframes_part = []  # Temporary list for the current part's DataFrames\n",
        "\n",
        "    print(f\"Processing part {idx + 1}/5...\")\n",
        "\n",
        "    # Loop through each subfolder in the current part and read the `.parquet` file\n",
        "    for subfolder in subfolders_part:\n",
        "        parquet_file = os.path.join(subfolder, 'part-0.parquet')\n",
        "        df_chunk = pd.read_parquet(parquet_file)\n",
        "        dataframes_part.append(df_chunk)\n",
        "\n",
        "    part_df = pd.concat(dataframes_part, ignore_index=True)\n",
        "    full_df_parts.append(part_df)\n",
        "    print(f\"Part {idx + 1} loaded and concatenated, shape: {part_df.shape}\")\n",
        "\n",
        "# Process the last 5 parts\n",
        "for idx in range(5, 10):\n",
        "    subfolders_part = subfolders_parts[idx]  # Get the current part\n",
        "    dataframes_part = []  # Temporary list for the current part's DataFrames\n",
        "\n",
        "    print(f\"Processing part {idx + 1}/10...\")\n",
        "\n",
        "    # Loop through each subfolder in the current part and read the `.parquet` file\n",
        "    for subfolder in subfolders_part:\n",
        "        parquet_file = os.path.join(subfolder, 'series_train.parquet')\n",
        "\n",
        "        df_chunk = pd.read_parquet(parquet_file)\n",
        "        dataframes_part.append(df_chunk)\n",
        "\n",
        "    part_df = pd.concat(dataframes_part, ignore_index=True)\n",
        "    full_df_parts.append(part_df)\n",
        "\n",
        "    print(f\"Part {idx + 1} loaded and concatenated, shape: {part_df.shape}\")\n",
        "\n",
        "# Concatenate all parts into the final full DataFrame\n",
        "full_df = pd.concat(full_df_parts, ignore_index=True)\n",
        "\n",
        "# Check the final DataFrame\n",
        "print(f\"Full DataFrame Shape: {full_df.shape}\")\n",
        "full_df.head()"
      ],
      "metadata": {
        "id": "jR3oii6X9Tuq",
        "outputId": "b4c00226-3e79-43bd-b79f-6a29727b6ae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing part 1/5...\n",
            "Part 1 loaded and concatenated, shape: (34848507, 13)\n",
            "Processing part 2/5...\n",
            "Part 2 loaded and concatenated, shape: (35791579, 13)\n",
            "Processing part 3/5...\n",
            "Part 3 loaded and concatenated, shape: (35509495, 13)\n",
            "Processing part 4/5...\n",
            "Part 4 loaded and concatenated, shape: (35216892, 13)\n",
            "Processing part 5/5...\n",
            "Part 5 loaded and concatenated, shape: (35088228, 13)\n",
            "Processing part 6/10...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/dataset/series_train.parquet/id=66f619e3/series_train.parquet'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d75fc92534f6>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Load the parquet file into a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mdf_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparquet_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# Append the DataFrame chunk to the list for this part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0mcheck_dtype_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mto_pandas_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"split_blocks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         path_or_handle, handles, filesystem = _get_path_or_handle(\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mfilesystem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# fsspec resources can also point to directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         handles = get_handle(\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/dataset/series_train.parquet/id=66f619e3/series_train.parquet'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YgObPKRq9TcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data sets\n",
        "#train_data = pd.read_parquet(\"/content/dataset/series_train.parquet\")\n",
        "test_data = pd.read_parquet(\"/content/dataset/series_test.parquet\")\n",
        "\n",
        "df = test_data\n",
        "df.to_csv('series_test.csv')\n",
        "\n",
        "print(\"Test data shape:\" + str(df.shape))\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values in Test Data:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(df.head())\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgDQDy8-vAlp",
        "outputId": "596e1520-d312-489e-831f-c974b39580f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data shape:(439726, 14)\n",
            "\n",
            "Missing Values in Test Data:\n",
            "step                   0\n",
            "X                      0\n",
            "Y                      0\n",
            "Z                      0\n",
            "enmo                   0\n",
            "anglez                 0\n",
            "non-wear_flag          0\n",
            "light                  0\n",
            "battery_voltage        0\n",
            "time_of_day            0\n",
            "weekday                0\n",
            "quarter                0\n",
            "relative_date_PCIAT    0\n",
            "id                     0\n",
            "dtype: int64\n",
            "   step         X         Y         Z      enmo     anglez  non-wear_flag  \\\n",
            "0     0  0.021536  0.022214 -1.022370  0.022853 -88.280762            0.0   \n",
            "1     1  0.022005  0.022187 -1.019740  0.020231 -88.241707            0.0   \n",
            "2     2  0.022240  0.022005 -1.019401  0.019893 -88.170067            0.0   \n",
            "3     3  0.021589  0.022578 -1.018177  0.018667 -88.250031            0.0   \n",
            "4     4  0.022005  0.023763 -1.014323  0.016848 -88.130775            0.0   \n",
            "\n",
            "       light  battery_voltage     time_of_day  weekday  quarter  \\\n",
            "0  53.000000      4188.000000  56940000000000        4        3   \n",
            "1  51.666668      4188.166504  56945000000000        4        3   \n",
            "2  50.333332      4188.333496  56950000000000        4        3   \n",
            "3  50.500000      4188.500000  56955000000000        4        3   \n",
            "4  33.166668      4181.000000  57235000000000        4        3   \n",
            "\n",
            "   relative_date_PCIAT        id  \n",
            "0                 41.0  00115b9f  \n",
            "1                 41.0  00115b9f  \n",
            "2                 41.0  00115b9f  \n",
            "3                 41.0  00115b9f  \n",
            "4                 41.0  00115b9f  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 439726 entries, 0 to 439725\n",
            "Data columns (total 14 columns):\n",
            " #   Column               Non-Null Count   Dtype   \n",
            "---  ------               --------------   -----   \n",
            " 0   step                 439726 non-null  uint32  \n",
            " 1   X                    439726 non-null  float32 \n",
            " 2   Y                    439726 non-null  float32 \n",
            " 3   Z                    439726 non-null  float32 \n",
            " 4   enmo                 439726 non-null  float32 \n",
            " 5   anglez               439726 non-null  float32 \n",
            " 6   non-wear_flag        439726 non-null  float32 \n",
            " 7   light                439726 non-null  float32 \n",
            " 8   battery_voltage      439726 non-null  float32 \n",
            " 9   time_of_day          439726 non-null  int64   \n",
            " 10  weekday              439726 non-null  int8    \n",
            " 11  quarter              439726 non-null  int8    \n",
            " 12  relative_date_PCIAT  439726 non-null  float32 \n",
            " 13  id                   439726 non-null  category\n",
            "dtypes: category(1), float32(9), int64(1), int8(2), uint32(1)\n",
            "memory usage: 21.4 MB\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}